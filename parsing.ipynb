{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import Necessary Libraries\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import regex as re\n",
    "from io import StringIO\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define Configurable Parameters\n",
    "# Customize these parameters based on your dataset and requirements.\n",
    "\n",
    "\n",
    "# Configuration Parameters\n",
    "dataset_folder = \"data\"                    # Root directory where experiment folders are located\n",
    "selected_experiment = \"2024-09-04_exp00_gamme_parasite_crypto\"           # Name of the experiment folder to process\n",
    "\n",
    "# Impedance Parameters to include; set to None to include all available parameters\n",
    "impedance_parameters = ['Param0', 'Param1', 'AbsZ', 'RealZ', 'ImagZ', 'PhaseZ']  \n",
    "\n",
    "output_csv_path = 'results.csv'  # Path to save the combined DataFrame as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define Helper Functions\n",
    "# These functions handle reading data files, extracting measurement times, and loading data for each well.\n",
    "\n",
    "\n",
    "def read_data_file(filename, impedance_parameters=None):\n",
    "    \"\"\"\n",
    "    Reads a data file and returns a pandas DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        filename (str): Path to the data file.\n",
    "        impedance_parameters (list or None): List of impedance parameters to include. If None, include all.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame or None: DataFrame containing the data or None if reading fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        # Identify the header line starting with 'Frequency'\n",
    "        header_line_index = None\n",
    "        for idx, line in enumerate(lines):\n",
    "            if line.strip().startswith('Frequency'):\n",
    "                header_line_index = idx\n",
    "                break\n",
    "        if header_line_index is None:\n",
    "            print(f\"No header found in file {filename}\")\n",
    "            return None\n",
    "        # Extract header and data\n",
    "        header_line = lines[header_line_index].strip()\n",
    "        columns = re.split(r'\\s+', header_line.replace('\\t', ' '))\n",
    "        data_str = ''.join(lines[header_line_index + 1:])\n",
    "        data = pd.read_csv(\n",
    "            StringIO(data_str),\n",
    "            sep=r'\\s+',\n",
    "            names=columns,\n",
    "            engine='python'\n",
    "        )\n",
    "        \n",
    "        if impedance_parameters:\n",
    "            # Filter columns to include only specified impedance parameters and Frequency\n",
    "            columns_to_include = ['Frequency'] + [param for param in impedance_parameters if param in data.columns]\n",
    "            data = data[columns_to_include]\n",
    "        else:\n",
    "            # Include all columns except 'Frequency' as parameters\n",
    "            columns_to_include = [col for col in data.columns if col != 'Frequency']\n",
    "        \n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {filename}: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_measurement_time_from_filename(filename):\n",
    "    \"\"\"\n",
    "    Extracts measurement time from the filename.\n",
    "    \n",
    "    Expected filename format: 'YYYYMMDD_HH-MM-SS_...'\n",
    "    \n",
    "    Parameters:\n",
    "        filename (str): Filename from which to extract the time.\n",
    "        \n",
    "    Returns:\n",
    "        datetime or None: Extracted measurement time or None if parsing fails.\n",
    "    \"\"\"\n",
    "    base = os.path.basename(filename)\n",
    "    parts = base.split('_')\n",
    "    if len(parts) >= 2:\n",
    "        datetime_str = parts[0] + '_' + parts[1]  # 'YYYYMMDD_HH-MM-SS'\n",
    "        try:\n",
    "            measurement_time = datetime.strptime(datetime_str, '%Y%m%d_%H-%M-%S')\n",
    "            return measurement_time\n",
    "        except ValueError:\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def load_well_data(well_path, impedance_parameters=None):\n",
    "    \"\"\"\n",
    "    Loads and processes impedance data for a specific well, including all frequencies.\n",
    "    \n",
    "    Parameters:\n",
    "        well_path (str): Path to the well's data folder.\n",
    "        impedance_parameters (list or None): List of impedance parameters to include. If None, include all.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame or None: DataFrame with Experiment, Well, Time, Frequency, and impedance parameters or None if no data found.\n",
    "    \"\"\"\n",
    "    data_files = glob.glob(os.path.join(well_path, '*.txt'))\n",
    "    if not data_files:\n",
    "        print(f\"No data files found in well path: {well_path}\")\n",
    "        return None\n",
    "\n",
    "    records = []\n",
    "\n",
    "    for data_file in data_files:\n",
    "        data = read_data_file(data_file, impedance_parameters)\n",
    "        if data is None:\n",
    "            continue\n",
    "        if 'Frequency' not in data.columns:\n",
    "            print(f\"'Frequency' column not found in file {data_file}\")\n",
    "            continue\n",
    "\n",
    "        # Extract the measurement time\n",
    "        measurement_time = extract_measurement_time_from_filename(data_file)\n",
    "        if measurement_time is None:\n",
    "            print(f\"Could not extract measurement time from filename: {data_file}\")\n",
    "            continue\n",
    "\n",
    "        # Melt the DataFrame to have one row per frequency and parameter\n",
    "        melted_df = data.melt(id_vars=['Frequency'], var_name='Parameter', value_name='Value')\n",
    "        melted_df['Experiment'] = selected_experiment\n",
    "        melted_df['Well'] = os.path.basename(well_path)\n",
    "        melted_df['Date'] = measurement_time\n",
    "\n",
    "        # Reorder columns\n",
    "        melted_df = melted_df[['Experiment', 'Well', 'Date', 'Frequency', 'Parameter', 'Value']]\n",
    "\n",
    "        records.append(melted_df)\n",
    "\n",
    "    if records:\n",
    "        combined_well_df = pd.concat(records, ignore_index=True)\n",
    "        return combined_well_df\n",
    "    else:\n",
    "        print(f\"No valid data extracted for well at {well_path}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected wells in '2024-09-04_exp00_gamme_parasite_crypto': ['A5', 'B5', 'D5', 'G1', 'G10', 'G11', 'G12']\n",
      "Total records before handling missing values: 6000600\n"
     ]
    }
   ],
   "source": [
    "# 4. Load and Process Data for All Wells\n",
    "# This section processes each well in the selected experiment and compiles the data into a combined DataFrame.\n",
    "\n",
    "\n",
    "# Initialize a list to store DataFrames for each well\n",
    "all_wells_data = []\n",
    "\n",
    "# Construct the path to the selected experiment\n",
    "experiment_path = os.path.join(dataset_folder, selected_experiment)\n",
    "\n",
    "# Verify that the experiment path exists\n",
    "if not os.path.exists(experiment_path):\n",
    "    raise FileNotFoundError(f\"Experiment folder '{selected_experiment}' not found in '{dataset_folder}'.\")\n",
    "\n",
    "# Automatically detect all wells in the experiment folder\n",
    "detected_wells = [name for name in os.listdir(experiment_path) if os.path.isdir(os.path.join(experiment_path, name))]\n",
    "\n",
    "if not detected_wells:\n",
    "    raise ValueError(f\"No well folders found in experiment folder '{selected_experiment}'.\")\n",
    "\n",
    "print(f\"Detected wells in '{selected_experiment}': {detected_wells}\")\n",
    "\n",
    "# Iterate through each detected well and load its data\n",
    "for well in detected_wells:\n",
    "    well_path = os.path.join(experiment_path, well)\n",
    "    df = load_well_data(well_path, impedance_parameters)\n",
    "    if df is not None:\n",
    "        all_wells_data.append(df)\n",
    "    else:\n",
    "        print(f\"No data found for well '{well}'.\")\n",
    "\n",
    "# Check if any well data was loaded\n",
    "if not all_wells_data:\n",
    "    raise ValueError(\"No data loaded for any of the wells in the selected experiment.\")\n",
    "\n",
    "# Combine all wells' DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(all_wells_data, ignore_index=True)\n",
    "\n",
    "print(f\"Total records before handling missing values: {len(combined_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "Experiment        0\n",
      "Well              0\n",
      "Date              0\n",
      "Frequency     30726\n",
      "Parameter         0\n",
      "Value         30726\n",
      "dtype: int64\n",
      "All missing values have been handled.\n",
      "Combined DataFrame preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Well</th>\n",
       "      <th>Date</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>AbsZ</th>\n",
       "      <th>ImagZ</th>\n",
       "      <th>Param0</th>\n",
       "      <th>Param1</th>\n",
       "      <th>PhaseZ</th>\n",
       "      <th>RealZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-09-04_exp00_gamme_parasite_crypto</td>\n",
       "      <td>A5</td>\n",
       "      <td>2024-09-04 11:58:56</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>410.069308</td>\n",
       "      <td>-376.597842</td>\n",
       "      <td>1036.291460</td>\n",
       "      <td>7.128751e-07</td>\n",
       "      <td>-1.163957</td>\n",
       "      <td>162.267960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-09-04_exp00_gamme_parasite_crypto</td>\n",
       "      <td>A5</td>\n",
       "      <td>2024-09-04 11:58:56</td>\n",
       "      <td>536.133611</td>\n",
       "      <td>388.759292</td>\n",
       "      <td>-354.346958</td>\n",
       "      <td>945.103483</td>\n",
       "      <td>6.960081e-07</td>\n",
       "      <td>-1.146872</td>\n",
       "      <td>159.912496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-09-04_exp00_gamme_parasite_crypto</td>\n",
       "      <td>A5</td>\n",
       "      <td>2024-09-04 11:58:56</td>\n",
       "      <td>574.878498</td>\n",
       "      <td>369.075884</td>\n",
       "      <td>-333.643009</td>\n",
       "      <td>863.252099</td>\n",
       "      <td>6.781016e-07</td>\n",
       "      <td>-1.129025</td>\n",
       "      <td>157.795236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-09-04_exp00_gamme_parasite_crypto</td>\n",
       "      <td>A5</td>\n",
       "      <td>2024-09-04 11:58:56</td>\n",
       "      <td>616.423370</td>\n",
       "      <td>350.799429</td>\n",
       "      <td>-314.359592</td>\n",
       "      <td>790.436551</td>\n",
       "      <td>6.595535e-07</td>\n",
       "      <td>-1.110956</td>\n",
       "      <td>155.686471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-09-04_exp00_gamme_parasite_crypto</td>\n",
       "      <td>A5</td>\n",
       "      <td>2024-09-04 11:58:56</td>\n",
       "      <td>660.970574</td>\n",
       "      <td>333.864605</td>\n",
       "      <td>-296.435264</td>\n",
       "      <td>725.706899</td>\n",
       "      <td>6.403643e-07</td>\n",
       "      <td>-1.092740</td>\n",
       "      <td>153.595900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Experiment Well                Date  \\\n",
       "0  2024-09-04_exp00_gamme_parasite_crypto   A5 2024-09-04 11:58:56   \n",
       "1  2024-09-04_exp00_gamme_parasite_crypto   A5 2024-09-04 11:58:56   \n",
       "2  2024-09-04_exp00_gamme_parasite_crypto   A5 2024-09-04 11:58:56   \n",
       "3  2024-09-04_exp00_gamme_parasite_crypto   A5 2024-09-04 11:58:56   \n",
       "4  2024-09-04_exp00_gamme_parasite_crypto   A5 2024-09-04 11:58:56   \n",
       "\n",
       "    Frequency        AbsZ       ImagZ       Param0        Param1    PhaseZ  \\\n",
       "0  500.000000  410.069308 -376.597842  1036.291460  7.128751e-07 -1.163957   \n",
       "1  536.133611  388.759292 -354.346958   945.103483  6.960081e-07 -1.146872   \n",
       "2  574.878498  369.075884 -333.643009   863.252099  6.781016e-07 -1.129025   \n",
       "3  616.423370  350.799429 -314.359592   790.436551  6.595535e-07 -1.110956   \n",
       "4  660.970574  333.864605 -296.435264   725.706899  6.403643e-07 -1.092740   \n",
       "\n",
       "        RealZ  \n",
       "0  162.267960  \n",
       "1  159.912496  \n",
       "2  157.795236  \n",
       "3  155.686471  \n",
       "4  153.595900  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5. Handle Missing Values and Save the Combined DataFrame to a CSV File\n",
    "# This step ensures that the DataFrame is complete and saves it to a CSV file for later use.\n",
    "\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = combined_df.isnull().sum()\n",
    "print(\"Missing values in each column:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Handle missing values if any\n",
    "if missing_values.any():\n",
    "    # Depending on the nature of missing data, choose an appropriate method\n",
    "    # For this example, we'll forward-fill and backward-fill\n",
    "    combined_df.sort_values(['Experiment', 'Well', 'Date', 'Frequency', 'Parameter'], inplace=True)\n",
    "    combined_df.fillna(method='ffill', inplace=True)\n",
    "    combined_df.fillna(method='bfill', inplace=True)\n",
    "\n",
    "    # Verify that all missing values are handled\n",
    "    if combined_df.isnull().sum().any():\n",
    "        print(\"Warning: There are still missing values after filling.\")\n",
    "    else:\n",
    "        print(\"All missing values have been handled.\")\n",
    "\n",
    "# Optionally, pivot the DataFrame to have Parameters as separate columns\n",
    "# This depends on downstream requirements\n",
    "pivot_df = combined_df.pivot_table(\n",
    "    index=['Experiment', 'Well', 'Date', 'Frequency'],\n",
    "    columns='Parameter',\n",
    "    values='Value'\n",
    ").reset_index()\n",
    "\n",
    "# Flatten the MultiIndex columns if necessary\n",
    "pivot_df.columns.name = None\n",
    "pivot_df.columns = [str(col) for col in pivot_df.columns]\n",
    "\n",
    "# Display the first few rows of the pivoted DataFrame\n",
    "print(\"Combined DataFrame preview:\")\n",
    "display(pivot_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined impedance data has been saved to 'results.csv'.\n"
     ]
    }
   ],
   "source": [
    "# 6. Save the Combined DataFrame to a CSV File\n",
    "# This step saves the processed DataFrame to a CSV file for later use.\n",
    "\n",
    "\n",
    "# Save the combined DataFrame to a CSV file\n",
    "pivot_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Combined impedance data has been saved to '{output_csv_path}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
